{"cells":[{"cell_type":"code","source":["from mlflow import MlflowClient\n","client = MlflowClient()\n","client.create_model_version(\n","        name=\"LD_Image_Detection\",\n","        source=<\"your-model-source-path\">,\n","        run_id=<\"your-run-id\">\n","    )"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"6c6a178b-ce6f-4353-add8-46a922e178ec"},{"cell_type":"code","source":["import requests\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import json\n","from PIL import Image\n","from io import BytesIO\n","import requests\n","\n","subscription_key = \"13b723adaded47b2bb95d90756692437\"\n","analyze_url = \"https://ld-image-detection.cognitiveservices.azure.com//vision/v3.1/analyze\"\n","image_url = \"https://www.pwc.com/jg/en/about-us/assets/jtmoty/jtmoty-08.jpg\"\n","headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n","params = {'visualFeatures':'Categories,Description,Objects'}\n","data = {'url': image_url}\n","\n","try:\n","    response = requests.post(analyze_url,headers = headers, params=params, json = data)\n","    response.raise_for_status()\n","    analysis = response.json()\n","except Exception as e:\n","    print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n","\n","#display\n","image = Image.open(BytesIO(requests.get(image_url).content))\n","plt.show(image)\n","plt.axis(\"off\")\n","plt.show()\n","print(analysis)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"670ece6c-9403-4c29-b6b4-f60d4a0b5622"},{"cell_type":"code","source":["analysis['objects']"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"ab407080-740a-4196-9970-b694b03a2aaf"},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","\n","def generate_box (image_url, boundRect):\n","    image = Image.open(BytesIO(requests.get(image_url).content))\n","    np_img = np.array(image)\n","    drawing = np_img\n","    for i in range(len(boundRect)):\n","        color = (255,0,0)\n","        cv2.rectangle(drawing, (int(boundRect[i][0]),int(boundRect[i][1])),(int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3])),color,2)\n","\n","        # show image\n","        plt.figure(figsize=(14,8))\n","        plt.imshow(drawing)\n","        plt.axis(\"off\")\n","        plt.show()\n","\n","generate_box(image_url,objects)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"78b603cf-2c05-4ac7-a787-12557b9e011f"},{"cell_type":"code","source":["# import library\n","\n","!pip install opencv-python-headless\n","\n","import requests\n","import matplotlib.pyplot as plt\n","import json\n","import io\n","from PIL import Image\n","from io import BytesIO\n","import requests\n","import numpy as np\n","import cv2\n","import base64\n","\n","############################################################\n","#IMAGE DETECTION#\n","#\n","# Functions\n","#\n","#\n","# object detection function\n","text = []\n","def obj_dim (analysis):\n","    objects = []\n","    for rec in analysis['objects']:\n","        k = []\n","        k.append(rec['rectangle']['x'])\n","        k.append(rec['rectangle']['y'])\n","        k.append(rec['rectangle']['w'])\n","        k.append(rec['rectangle']['h'])\n","        objects.append(k)\n","    return objects\n","#\n","#\n","# generate red box around the detected object\n","def generate_box (image_path, boundRect):\n","    _image = Image.open(image_path)\n","    np_img = np.array(_image)\n","    drawing = np_img\n","    for i in range(len(boundRect)):\n","        color = (255,0,0)\n","        cv2.rectangle(drawing, (int(boundRect[i][0]),int(boundRect[i][1])),(int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3])),color,2)\n","        plt.figure(figsize=(14,8))\n","        plt.imshow(drawing)\n","        plt.axis(\"off\")\n","        plt.show()\n","#   \n","#\n","# generate a function to crop images\n","def img_crop (image_path,image_dim):\n","    image = Image.open(image_path)\n","    cropped_img = []\n","    for i in range(len(image_dim)):\n","        x,y,w,h = image_dim[i]\n","        img = image.crop((x,y,x+w,y+h))\n","        cropped_img.append(img)\n","    return cropped_img\n","\n","#\n","#\n","# recursive function to identity object\n","\n","def rec_obj (image):\n","    image_path = image\n","    # Credentials for Azure AI services\n","    subscription_key = \"13b723adaded47b2bb95d90756692437\"\n","    analyze_url = \"https://ld-image-detection.cognitiveservices.azure.com//vision/v3.1/analyze\"\n","    headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n","\n","    # parameters for ML\n","    params = {'visualFeatures':'Categories,Description,Objects'}\n","\n","    files = {'image':open(image_path,'rb')}\n","    print(files)\n","    error = \"\"\n","    # Run model on the image and return the params in json format\n","    try:\n","        response = requests.post(analyze_url,headers = headers, params=params, files=files)\n","        response.raise_for_status()\n","        analysis = response.json()\n","        # return analysis\n","        print(analysis)\n","        text.append(analysis['description']['captions'])\n","        # If analysis of the image detects object\n","        if analysis['objects'] != []:\n","            print('Image Detected')\n","\n","            # call obj dim store fucntion\n","            objects = obj_dim(analysis)\n","\n","            # call generate red box function\n","            generate_box(image_path,objects)\n","\n","            # # create a temp folder to store the cropped images\n","            cropped_img_arr = img_crop(image_path,objects)\n","            if cropped_img_arr != []:\n","                 for i in range(len(cropped_img_arr)):\n","                     cropped_img_arr[i].save(\"/lakehouse/default/Files/Image Detection/Images/img0\"+str(i)+\".jpg\")\n","                     rec_obj(\"/lakehouse/default/Files/Image Detection/Images/img0\"+str(i)+\".jpg\")\n","        else:\n","            print(\"\")\n","            #break       \n","    except requests.HTTPError as e:\n","        # Handle the HTTPError here\n","        error = str(f\"HTTP Error: {e}\")\n","        \n","\n","    print(error)  \n","   \n","rec_obj(\"/lakehouse/default/Files/Image Detection/Image.jpg\")\n","print(text)\n","# print(output)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"0f87ac57-a8cf-4670-94b1-96595f3c5497"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python"},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"}},"nbformat":4,"nbformat_minor":5}